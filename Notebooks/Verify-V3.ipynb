{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mat Scalpello Dundee University MSc data Science Project 2020\n",
    "#Orignal Code from Graph Algorithms - Mark Needham and Amy Hodler 2019 (O'Reilly Media)\n",
    "#Modifications by Mat Scalpello as indicated\n",
    "\n",
    "# Code to test V3-V4 model\n",
    "#You will need to add paths to a model and for file output\n",
    "# Test model link prediction and community detection features\n",
    "# Test triangles and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "graph = Graph(\"bolt://localhost\", auth=(\"neo4j\", \"123\"))\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "#You will need to put in a file path to the model location\n",
    "filename = 'file path here V3.sav'\n",
    "# Feature column names\n",
    "columns = [\n",
    "    \"cn\",\"aa\", \"pa\", \"tn\",\"ra\", # graph features\n",
    "    \"lp\", \"lv\",\n",
    "    \"minT\", \"maxT\", \"minC\", \"maxC\"    # triangle features     \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, actual):\n",
    "    return pd.DataFrame({\n",
    "        \"Measure\": [\"Accuracy\", \"Precision\", \"Recall\"],\n",
    "        \"Score\": [accuracy_score(actual, predictions), \n",
    "                  precision_score(actual, predictions), \n",
    "                  recall_score(actual, predictions)]\n",
    "    })\n",
    "\n",
    "def feature_importance(columns, classifier):        \n",
    "    display(\"Feature Importance\")\n",
    "    df = pd.DataFrame({\n",
    "        \"Feature\": columns,\n",
    "        \"Importance\": classifier.feature_importances_\n",
    "    })\n",
    "    df = df.sort_values(\"Importance\", ascending=False)    \n",
    "    ax = df.plot(kind='bar', x='Feature', y='Importance', legend=None)\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "# Added Resource allocation and Adamic Adar\n",
    "def create_LP_features(data, rel_type):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "           pair.node2 AS node2,\n",
    "           algo.linkprediction.commonNeighbors(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS cn,\n",
    "           algo.linkprediction.adamicAdar(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS aa,\n",
    "           algo.linkprediction.preferentialAttachment(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS pa,\n",
    "           algo.linkprediction.totalNeighbors(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS tn,\n",
    "           algo.linkprediction.resourceAllocation(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS ra\n",
    "               \n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    features = graph.run(query, {\"pairs\": pairs, \"relType\": rel_type}).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])\n",
    "\n",
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "def create_community_features(data, triangles_prop, coefficient_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    apoc.coll.min([p1[$trianglesProp], p2[$trianglesProp]]) AS minT,\n",
    "    apoc.coll.max([p1[$trianglesProp], p2[$trianglesProp]]) AS maxT,\n",
    "    apoc.coll.min([p1[$coefficientProp], p2[$coefficientProp]]) AS minC,\n",
    "    apoc.coll.max([p1[$coefficientProp], p2[$coefficientProp]]) AS maxC\n",
    "    \"\"\"    \n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]    \n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"trianglesProp\": triangles_prop,\n",
    "    \"coefficientProp\": coefficient_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])\n",
    "\n",
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "def communitydetection_features(data, partition_prop, louvain_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    algo.linkprediction.sameCommunity(p1, p2, $partitionProp) AS lp,    \n",
    "    algo.linkprediction.sameCommunity(p1, p2, $louvainProp) AS lv\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"partitionProp\": partition_prop,\n",
    "    \"louvainProp\": louvain_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])\n",
    "\n",
    "# MSCALPELLO compare surname ids and return a 1 if the same\n",
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "def samename_features(data, samename_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    algo.linkprediction.sameCommunity(p1, p2, $samenameProp) AS sn\n",
    "\"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"samenameProp\": samename_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "#Load negative links for a subgraph\n",
    "#You need to put a name in here\n",
    "load_links = graph.run(\"\"\"\n",
    "MATCH (p1:Person {FullName: \"Name here\"})\n",
    "WHERE (p1)-[:Knows]-()\n",
    "MATCH (p1)-[:Knows*1..3]-(p2:Person)\n",
    "WHERE not((p1)-[:Knows]-(p2))\n",
    "RETURN p1.connectionid AS node1, p2.connectionid AS node2, 0 AS label\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_links= load_links.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "#Used for including hand picked node pairs that the model \n",
    "#might predict positively against\n",
    "#Load missing link data - you will need to include a file path\n",
    "nolinks = pd.read_csv('file path here noedges.csv')\n",
    "\n",
    "#MSCALPELLO\n",
    "# Add the nodes with no link\n",
    "all_links = load_links.append(nolinks,ignore_index=True)\n",
    "\n",
    "#MSCALPELLO\n",
    "# Apply graphs algorithms to node pairs\n",
    "# use the main graph not a sub-graph\n",
    "all_links= create_LP_features(all_links,\"Knows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#MSCALPELLO - Added iterations on LP to ensure it will converge\n",
    "# Apply community features to data\n",
    "# Setup label propagation\n",
    "graph.run(\"\"\"\n",
    "CALL algo.labelPropagation(\"Person\", \"Knows\", \"BOTH\",\n",
    "{iterations:20, partitionProperty: \"labelprop\"});\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.run(\"\"\"\n",
    "CALL algo.louvain.stream(\"Person\", \"Knows\", {includeIntermediateCommunities:true})\n",
    "YIELD nodeId, community, communities\n",
    "WITH algo.getNodeById(nodeId) AS node, communities[0] AS smallestCommunity\n",
    "SET node.louvain = smallestCommunity;\n",
    "\"\"\").stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = communitydetection_features(all_links, \"community\", \"louvain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Triangle features to node pairs\n",
    "# Setup data in graphDB\n",
    "graph.run(\"\"\"\n",
    "CALL algo.triangleCount('Person', 'Knows', { write:true,\n",
    "writeProperty:'triangles', clusteringCoefficientProperty:'clustercoef'});\n",
    "\"\"\").to_data_frame()\n",
    "\n",
    "all_links = create_community_features(all_links,\"triangles\",\"clustercoef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "#save output data\n",
    "all_links.to_csv('file path here Verify_V3.csv')\n",
    "\n",
    "#MSCALPELLO\n",
    "#Run the classifier\n",
    "predictions=lrclassifier.predict(all_links[columns])\n",
    "predictpct=lrclassifier.predict_proba(all_links[columns])\n",
    "\n",
    "#MSCALPELLO\n",
    "#save output data predictions\n",
    "pd.DataFrame(predictions).to_csv('file path here V3_predictions.csv')\n",
    "\n",
    "#MSCALPELLO\n",
    "#save output data predictions - percentages\n",
    "pd.DataFrame(predictpct).to_csv('file path here V3_predictpct.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
