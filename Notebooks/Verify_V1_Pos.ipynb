{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mat Scalpello Dundee University MSc data Science Project 2020\n",
    "#Original Code from Graph Algorithms - Mark Needham and Amy Hodler 2019 (O'Reilly Media)\n",
    "#Modifications by Mat Scalpello as indicated\n",
    "\n",
    "# Code to test V1 model with positive (existing links)\n",
    "#You will need to add paths to a model and for file output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "graph = Graph(\"bolt://localhost\", auth=(\"neo4j\", \"123\"))\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "#you will need to add a path to a model\n",
    "filename = 'Path to model V1.sav'\n",
    "lrclassifier = pickle.load(open(filename,'rb'))\n",
    "# Feature column names\n",
    "columns = [\n",
    "    \"cn\",\"aa\", \"pa\", \"tn\",\"ra\" # graph features\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(predictions, actual):\n",
    "    return pd.DataFrame({\n",
    "        \"Measure\": [\"Accuracy\", \"Precision\", \"Recall\"],\n",
    "        \"Score\": [accuracy_score(actual, predictions), \n",
    "                  precision_score(actual, predictions), \n",
    "                  recall_score(actual, predictions)]\n",
    "    })\n",
    "\n",
    "def feature_importance(columns, classifier):        \n",
    "    display(\"Feature Importance\")\n",
    "    df = pd.DataFrame({\n",
    "        \"Feature\": columns,\n",
    "        \"Importance\": classifier.feature_importances_\n",
    "    })\n",
    "    df = df.sort_values(\"Importance\", ascending=False)    \n",
    "    ax = df.plot(kind='bar', x='Feature', y='Importance', legend=None)\n",
    "    ax.xaxis.set_label_text(\"\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "# Added Resource allocation and Adamic Adar\n",
    "def create_LP_features(data, rel_type):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "           pair.node2 AS node2,\n",
    "           algo.linkprediction.commonNeighbors(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS cn,\n",
    "           algo.linkprediction.adamicAdar(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS aa,\n",
    "           algo.linkprediction.preferentialAttachment(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS pa,\n",
    "           algo.linkprediction.totalNeighbors(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS tn,\n",
    "           algo.linkprediction.resourceAllocation(\n",
    "               p1, p2, {relationshipQuery: $relType}) AS ra\n",
    "               \n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    features = graph.run(query, {\"pairs\": pairs, \"relType\": rel_type}).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])\n",
    "\n",
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "def create_community_features(data, triangles_prop, coefficient_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    apoc.coll.min([p1[$trianglesProp], p2[$trianglesProp]]) AS minT,\n",
    "    apoc.coll.max([p1[$trianglesProp], p2[$trianglesProp]]) AS maxT,\n",
    "    apoc.coll.min([p1[$coefficientProp], p2[$coefficientProp]]) AS minC,\n",
    "    apoc.coll.max([p1[$coefficientProp], p2[$coefficientProp]]) AS maxC\n",
    "    \"\"\"    \n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]    \n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"trianglesProp\": triangles_prop,\n",
    "    \"coefficientProp\": coefficient_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])\n",
    "\n",
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "def communitydetection_features(data, partition_prop, louvain_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    algo.linkprediction.sameCommunity(p1, p2, $partitionProp) AS lp,    \n",
    "    algo.linkprediction.sameCommunity(p1, p2, $louvainProp) AS lv\n",
    "    \"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"partitionProp\": partition_prop,\n",
    "    \"louvainProp\": louvain_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])\n",
    "\n",
    "# MSCALPELLO compare surname ids and return a 1 if the same\n",
    "# MSCALPELLO Modified to use connectionid and an appropriate index\n",
    "# Using NEO4J IDs does not work consistently\n",
    "def samename_features(data, samename_prop):\n",
    "    query = \"\"\"\n",
    "    UNWIND $pairs AS pair\n",
    "    MATCH (p1:Person) \n",
    "    USING INDEX p1:Person(connectionid) \n",
    "    WHERE p1.connectionid = pair.node1\n",
    "    MATCH (p2:Person) \n",
    "    USING INDEX p2:Person(connectionid) \n",
    "    WHERE p2.connectionid = pair.node2\n",
    "    RETURN pair.node1 AS node1,\n",
    "    pair.node2 AS node2,\n",
    "    algo.linkprediction.sameCommunity(p1, p2, $samenameProp) AS sn\n",
    "\"\"\"\n",
    "    pairs = [{\"node1\": node1, \"node2\": node2}  for node1,node2 in data[[\"node1\", \"node2\"]].values.tolist()]\n",
    "    params = {\n",
    "    \"pairs\": pairs,\n",
    "    \"samenameProp\": samename_prop\n",
    "    }\n",
    "    features = graph.run(query, params).to_data_frame()\n",
    "    features = features.drop_duplicates()\n",
    "    return pd.merge(data, features, on = [\"node1\", \"node2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "#Load data - all existing links for a subgraph\n",
    "load_links = graph.run(\"\"\"\n",
    "MATCH (p1:Person {FullName: 'Name Here' })-[*1..2]-(p2:Person)-[:Knows]-(p3:Person)\n",
    "RETURN p2.connectionid AS node1, p3.connectionid AS node2, 1 AS label\n",
    "\"\"\").to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links= load_links.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSCALPELLO\n",
    "# Apply graphs algorithms to node pairs\n",
    "# use the main graph not a sub-graph\n",
    "all_links= create_LP_features(all_links,\"Knows\")\n",
    "\n",
    "#Save the output data\n",
    "all_links.to_csv('file path here /Verify_V1_POS.csv')\n",
    "\n",
    "#MSCALPELLO\n",
    "#Run the classifier\n",
    "predictions=lrclassifier.predict(all_links[columns])\n",
    "predictpct=lrclassifier.predict_proba(all_links[columns])\n",
    "\n",
    "#MSCALPELLO\n",
    "#Save the output data - predictions\n",
    "pd.DataFrame(predictions).to_csv('file path here /Verify_V1_POS_P.csv')\n",
    "\n",
    "#MSCALPELLO\n",
    "#Save the output data - predictions\n",
    "pd.DataFrame(predictpct).to_csv('file path here /Verify_V1_POS_Pct.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
